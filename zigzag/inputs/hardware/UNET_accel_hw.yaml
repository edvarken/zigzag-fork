name: UNET_accel_hw

memories:
  rf_1B_A: # 8bit Activations=Inputs loading regs
    size: 8
    r_bw: 8
    w_bw: 8
    r_cost: 0.01
    w_cost: 0.01
    area: 0
    r_port: 1
    w_port: 1
    rw_port: 0
    latency: 1
    auto_cost_extraction: False
    operands: [I1]
    ports:
      - fh: w_port_1
        tl: r_port_1
    served_dimensions: [] # Input regs fully unrolled over all MACs

  rf_2B_O: # 16bit output=accumulation regs
    size: 16
    r_bw: 16
    w_bw: 16
    r_cost: 0.02
    w_cost: 0.02
    area: 0
    r_port: 2
    w_port: 2
    rw_port: 0
    latency: 1
    operands: [O]
    ports:
      - fh: w_port_1
        tl: r_port_1
        fl: w_port_2
        th: r_port_2
    served_dimensions: [] # accumulation registers fully unrolled over all MACs

  rf_1B_W: # 4bit Weights loading regs, however 4bit is only for Conv, but 8bit needed for Gemm :(
    size: 8
    r_bw: 8
    w_bw: 8
    r_cost: 0.01
    w_cost: 0.01
    area: 0
    r_port: 1
    w_port: 1
    rw_port: 0
    latency: 1
    auto_cost_extraction: False
    operands: [I2]
    ports:
      - fh: w_port_1
        tl: r_port_1
    served_dimensions: [] # Weight regs fully unrolled over all MACs

  sram_2MB_A: # 2MB inputs/activations buffer
    size: 16777216
    r_bw: 64
    w_bw: 64
    r_cost: 416.16
    w_cost: 378.4
    area: 0
    r_port: 1
    w_port: 1
    rw_port: 0
    latency: 1
    min_r_granularity: 64
    min_w_granularity: 64
    operands: [I1]
    ports:
      - fh: w_port_1
        tl: r_port_1
    served_dimensions: [D1, D2, D3] # only 1 instance, that serves all D1, D2 and D3 dimensions

  sram_2MB_W: # 2MB weights buffer
    size: 16777216
    r_bw: 64
    w_bw: 64
    r_cost: 416.16
    w_cost: 378.4
    area: 0
    r_port: 1
    w_port: 1
    rw_port: 0
    latency: 1
    min_r_granularity: 64
    min_w_granularity: 64
    operands: [I2]
    ports:
      - fh: w_port_1
        tl: r_port_1
    served_dimensions: [D1, D2, D3] # only 1 instance, that serves all D1, D2, D3 dimensions

  
  sram_4MB_O: # 4MB output buffer
    size: 33554432
    r_bw: 64
    w_bw: 64
    r_cost: 416.16
    w_cost: 378.4
    area: 0
    r_port: 0
    w_port: 0
    rw_port: 1
    latency: 1
    min_r_granularity: 64
    min_w_granularity: 64
    operands: [O]
    ports:
      - fh: rw_port_1 # this is about Outputs, so needs both (fh, tl) and (fl, th)
        tl: rw_port_1
        fl: rw_port_1
        th: rw_port_1
    served_dimensions: [D1, D2, D3]

  dram:
    size: 10000000000
    r_bw: 64
    w_bw: 64
    r_cost: 700
    w_cost: 750
    area: 0
    r_port: 0
    w_port: 0
    rw_port: 1
    latency: 1
    operands: [I1, I2, O]
    ports:
      - fh: rw_port_1
        tl: rw_port_1
      - fh: rw_port_1
        tl: rw_port_1
      - fh: rw_port_1 # this is about Outputs, so needs both (fh, tl) and (fl, th)
        tl: rw_port_1
        fl: rw_port_1
        th: rw_port_1
    served_dimensions: [D1, D2, D3] # this means there is only 1 instance of DRAM, and it serves all D1 and D2 dimensions

operational_array:
  multiplier_energy: 0.04 # pJ
  multiplier_area: 1 # unit
  dimensions: [D1, D2, D3]
  sizes: [3, 3, 64]
